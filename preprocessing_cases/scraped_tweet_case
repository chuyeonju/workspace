import pandas as pd
import os
import numpy as np
import json
from nltk.tokenize import RegexpTokenizer


df_mentions = df[['mentions']]
df_mentions['mentions'] = df_mentions['mentions'].apply(lambda x: ast.literal_eval(x))

mt_name = []
for i,k in enumerate(df_mentions['mentions']):
    try:
#         print(k[0]['screen_name'])
        tmp.append(k[0]['screen_name'])
    except:
#         print('None')
        tmp.append('None')
# print(tmp)
df['mention_name'] = mt_name

def _removeNonAscii(s):
    return "".join(i for i in s if  ord(i)<128)

def make_lower_case(text):
    return text.lower()

def remove_stop_words(text):
    text = text.split()
    stops = set(stopwords.words("english"))
    text = [w for w in text if not w in stops]
    text = " ".join(text)
    return text

def remove_html(text):
    html_pattern = re.compile('<.*?>')
    return html_pattern.sub(r'', text)

def remove_punctuation(text):
    tokenizer = RegexpTokenizer(r'[a-zA-Z]+')
    text = tokenizer.tokenize(text)
    text = " ".join(text)
    return text
    
df['cleaned'] = df['text'].apply(_removeNonAscii)
df['cleaned'] = df.cleaned.apply(make_lower_case)
df['cleaned'] = df.cleaned.apply(remove_stop_words)
df['cleaned'] = df.cleaned.apply(remove_punctuation)
df['cleaned'] = df.cleaned.apply(remove_html)



# Basic Cleaning Text Function
def CleanText(readData, Num=False):

    # Remove Retweets 
    text = re.sub('RT @[\w_]+: ', '', str(readData))

    # Remove Mentions
    text = re.sub('@[\w_]+', '', text)

    # Remove or Replace URL 
    text = re.sub(r"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\(\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+", ' ', text) 
    # http로 시작되는 url
    text = re.sub(r"[-a-zA-Z0-9@:%._\+~#=]{1,256}\.[a-zA-Z0-9()]{2,6}\b([-a-zA-Z0-9()@:%_\+.~#?&//=]*)", ' ', text) 
    # http로 시작되지 않는 url
    
    # Remove Hashtag
    text = re.sub('[#]+[0-9a-zA-Z_]+', ' ', text)

    # Remove Garbage Words (ex. &lt, &gt, etc)
    text = re.sub('[&]+[a-z]+', ' ', text)
    
    # Remove Garbage Words (ex. &lt, &gt, etc)
    text = re.sub('any[\w_]+', ' ', text)
    text = re.sub('42k|12b|u2026|kind of|soon|way|2b|please|any|retweet|share', ' ', text)
    
#     # Remove Special Characters
    text = re.sub('[^a-zA-Z]', ' ', text) #^something가 아닌 문자열은 모두 없애줌
    
    # Remove newline
    text = text.replace('\n',' ')
    text = text.replace('\nn',' ')
    text = text.replace(r'\u',' ')
    
    
    #remove emojis from tweet
    text = emoji_pattern.sub(r'', text)
    
    
    if Num is True:
        # Remove Numbers
        text = re.sub(r'\d+',' ',text)
    
    text = re.sub(r"\b[a-zA-Z]\b"," ", text)


#     # Remove multi spacing & Reform sentence
    text = ' '.join(text.split()) 
       
    return text


try:
    import cPickle as pickle
except ImportError: 
    import pickle
import re


with open('Emoji_Dict.p', 'rb') as fp:
    Emoji_Dict = pickle.load(fp)
Emoji_Dict = {v: k for k, v in Emoji_Dict.items()}

def convert_emojis_to_word(text):
    for emot in Emoji_Dict:
        text = re.sub(r'('+emot+')', "_".join(Emoji_Dict[emot].replace(",","").replace(":","").split()), text)
    return text
    
#HappyEmoticons
emoticons_happy = set([
    ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',
    ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',
    '=-3', '=3', ':-))', ":'-)", ":')", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',
    'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',
    '<3'
    ])
# Sad Emoticons
emoticons_sad = set([
    ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',
    ':-[', ':-<', '=\\', '=/', '>:(', ':(', '>.<', ":'-(", ":'(", ':\\', ':-c',
    ':c', ':{', '>:\\', ';('
    ])


emoji_pattern = re.compile("["
         u"\U0001F600-\U0001F64F"  # emoticons
         u"\U0001F300-\U0001F5FF"  # symbols & pictographs
         u"\U0001F680-\U0001F6FF"  # transport & map symbols
         u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
         u"\U00002702-\U000027B0"
         u"\U000024C2-\U0001F251"
         "]+", flags=re.UNICODE)
         
 
 #combine sad and happy emoticons
emoticons = emoticons_happy.union(emoticons_sad)


mask = df['text'].isin(['great depression', 'economic depression', 'during the depression', 'depression era', 'tropical depression', 'depressed real estate']) 
mock_data[~mask].head() # ~를 포함하게 되면 mask의 값을 제외, ~을 제외하면 mask의 값을 포함입니다.
